{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dc48d0",
   "metadata": {},
   "source": [
    "<center> <h1 style='color:fuchsia'> Apprentissage automatique-Classification (Suite)</h1></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba029695",
   "metadata": {},
   "source": [
    "# 1. La validation Croisée (k-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282281f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nump\n",
    "import pandas as pd\n",
    "try:\n",
    "    fichier='pima.csv'\n",
    "    col=['NbGross','Glucos','PresArt','EpaissPli','Insuline','IMC','Pedigree','Age','Class']\n",
    "    data=pd.read_csv(fichier, names=col)\n",
    "    print(data)\n",
    "except:\n",
    "    print('Erreur de lecture')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75480bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# séparation des données en X et Y\n",
    "dataML = data.values\n",
    "\n",
    "X = dataML[:, :-1]\n",
    "Y = dataML[:, -1]\n",
    "\n",
    "acc = []\n",
    "precision = []\n",
    "rappel = []\n",
    "f1score = []\n",
    "\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "for train_index, test_index in KF.split(X):\n",
    "\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    model = DTC(criterion='gini')\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "    rappel.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "    f1score.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(f'Accuracy = {accuracy_score(y_test, y_pred):.2f}')\n",
    "    print(f'Precision = {precision[-1]:.2f}')\n",
    "    print(f'Recall = {rappel[-1]:.2f}')\n",
    "    print(f'F1-Score = {f1score[-1]:.2f}')\n",
    "\n",
    "print(f'\\nLa moyenne des métriques :\\n---------------------------')\n",
    "print(f'Accuracy moyenne : {sum(acc) / len(acc):.2f}%')\n",
    "print(f'Precision moyenne : {sum(precision) / len(precision):.2f}%')\n",
    "print(f'Rappel moyen : {sum(rappel) / len(rappel):.2f}%')\n",
    "print(f'F1-Score moyen : {sum(f1score) / len(f1score):.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envAI1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
